[load_model_and_tokenizer] Loading model and tokenizer...
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:04,  2.26s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.12s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.45s/it]
[32m
[QUARK-INFO]: C++ kernel compilation check start.[0m
[32m
[QUARK-INFO]: C++ kernel build directory /home/wanghao/.cache/torch_extensions/py310_cpu/kernel_ext[0m
[32m
[QUARK-INFO]: C++ kernel loading. First-time compilation may take a few minutes...[0m
[92mSuccessfully preprocessed all matching files.[0m
[32m
[QUARK-INFO]: C++ kernel compilation is already complete. Ending the C++ kernel compilation check. Total time: 0.2533 seconds[0m
[32m
[QUARK-INFO]: Configuration checking start.[0m
[32m
[QUARK-INFO]: Configuration checking end. The configuration is effective. This is weight quantization and activation static quantization.[0m
[32m
[QUARK-INFO]: 

====== QuantizeModel GPU Memory Profiling Before Forward ======
|        Total Allocated Memory:         |       7.52GB       |
|         Total Reserved Memory:         |       7.53GB       |
===============================================================

[0m
[32m
[QUARK-INFO]: Quantizing with the quantization configuration:
Config(
    global_quant_config=QuantizationConfig(
        input_tensors=QuantizationSpec(
            dtype=Dtype.int4,
            observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>,
            is_dynamic=False,
            qscheme=QSchemeType.per_tensor,
            ch_axis=None,
            group_size=None,
            symmetric=True,
            round_method=RoundType.round,
            scale_type=ScaleType.float,
            scale_format=None,
            scale_calculation_mode=None,
            qat_spec=None,
            mx_element_dtype=None,
            zero_point_type=ZeroPointType.int32,
            is_scale_quant=False,
        ),
        output_tensors=None,
        weight=QuantizationSpec(
            dtype=Dtype.int4,
            observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>,
            is_dynamic=False,
            qscheme=QSchemeType.per_tensor,
            ch_axis=None,
            group_size=None,
            symmetric=True,
            round_method=RoundType.round,
            scale_type=ScaleType.float,
            scale_format=None,
            scale_calculation_mode=None,
            qat_spec=None,
            mx_element_dtype=None,
            zero_point_type=ZeroPointType.int32,
            is_scale_quant=False,
        ),
        bias=None,
        target_device=None,
    ),
    layer_type_quant_config={},
    layer_quant_config={'*k_proj': QuantizationConfig(input_tensors=QuantizationSpec(dtype=<Dtype.int4: 'int4'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), output_tensors=QuantizationSpec(dtype=<Dtype.int4: 'int4'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), weight=QuantizationSpec(dtype=<Dtype.int4: 'int4'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), bias=None, target_device=None), '*v_proj': QuantizationConfig(input_tensors=QuantizationSpec(dtype=<Dtype.int4: 'int4'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), output_tensors=QuantizationSpec(dtype=<Dtype.int4: 'int4'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), weight=QuantizationSpec(dtype=<Dtype.int4: 'int4'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), bias=None, target_device=None)},
    kv_cache_quant_config={'*k_proj': QuantizationConfig(input_tensors=QuantizationSpec(dtype=<Dtype.int4: 'int4'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), output_tensors=QuantizationSpec(dtype=<Dtype.int4: 'int4'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), weight=QuantizationSpec(dtype=<Dtype.int4: 'int4'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), bias=None, target_device=None), '*v_proj': QuantizationConfig(input_tensors=QuantizationSpec(dtype=<Dtype.int4: 'int4'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), output_tensors=QuantizationSpec(dtype=<Dtype.int4: 'int4'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), weight=QuantizationSpec(dtype=<Dtype.int4: 'int4'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), bias=None, target_device=None)},
    kv_cache_group=[
    ],
    min_kv_scale=0.0,
    softmax_quant_spec=None,
    exclude=['lm_head'],
    algo_config=None,
    quant_mode=QuantizationMode.eager_mode,
    log_severity_level=1,
    version="0.10",
)[0m
[32m
[QUARK-INFO]: In-place OPs replacement start.[0m
[32m
[QUARK-INFO]: Module exclusion from quantization summary:
|      Exclude pattern       | Number of modules excluded |
|          lm_head           |             0              |
[0m
[Warning] When the dtype of your model is float32 and custom_mode = 'fp8', a version of torch (rocm) lower than 2.4.0 will result in calculation errors of 'torch._scaled_mm', 
If you find that the ppl value is large, try to increase the version of torch. Besides, you should ensure your torch version matches your rocm to prevent errors.
[load_model_and_tokenizer] Applying quark-int4 quantization using Quark...
  0%|          | 0/548 [00:00<?, ?it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 278/548 [00:00<00:00, 2776.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<00:00, 2716.24it/s]
[32m
[QUARK-INFO]: Module replacement for quantization summary:
|            Original module             |  Number original   |  Number replaced   |
|                 Conv2d                 |         0          |         0          |
|                 Linear                 |        253         |        253         |
|            ConvTranspose2d             |         0          |         0          |
|               Embedding                |         1          |         0          |
|              EmbeddingBag              |         0          |         0          |
|            OptimizedModule             |         1          |         0          |
|            Qwen3ForCausalLM            |         1          |         0          |
|               Qwen3Model               |         1          |         0          |
|               ModuleList               |         1          |         0          |
|           Qwen3DecoderLayer            |         36         |         0          |
|             Qwen3Attention             |         36         |         0          |
|              Qwen3RMSNorm              |        145         |         0          |
|                Qwen3MLP                |         36         |         0          |
|             SiLUActivation             |         36         |         0          |
|          Qwen3RotaryEmbedding          |         1          |         0          |
[0m
[32m
[QUARK-INFO]: In-place OPs replacement end.[0m
[32m
[QUARK-INFO]: Calibration start.[0m
  0%|          | 0/32 [00:00<?, ?it/s]W1104 16:00:55.713000 222097 site-packages/torch/_dynamo/convert_frame.py:1016] [41/8] torch._dynamo hit config.recompile_limit (8)
W1104 16:00:55.713000 222097 site-packages/torch/_dynamo/convert_frame.py:1016] [41/8]    function: 'torch_dynamo_resume_in_forward_at_202' (/home/wanghao/miniconda/envs/rocm_ai/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py:202)
W1104 16:00:55.713000 222097 site-packages/torch/_dynamo/convert_frame.py:1016] [41/8]    last reason: 41/7: past_key_values.layers[7].is_initialized == False      
W1104 16:00:55.713000 222097 site-packages/torch/_dynamo/convert_frame.py:1016] [41/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W1104 16:00:55.713000 222097 site-packages/torch/_dynamo/convert_frame.py:1016] [41/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
  3%|â–Ž         | 1/32 [01:36<49:42, 96.21s/it]W1104 16:01:06.807000 222097 site-packages/torch/_dynamo/convert_frame.py:1016] [15/8] torch._dynamo hit config.recompile_limit (8)
W1104 16:01:06.807000 222097 site-packages/torch/_dynamo/convert_frame.py:1016] [15/8]    function: 'observe' (/home/wanghao/miniconda/envs/rocm_ai/lib/python3.10/site-packages/quark/torch/quantization/tensor_quantize.py:240)
W1104 16:01:06.807000 222097 site-packages/torch/_dynamo/convert_frame.py:1016] [15/8]    last reason: 15/3: expected type of 'X' to be a tensor type, ' but found <class 'torch.nn.parameter.Parameter'>
W1104 16:01:06.807000 222097 site-packages/torch/_dynamo/convert_frame.py:1016] [15/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W1104 16:01:06.807000 222097 site-packages/torch/_dynamo/convert_frame.py:1016] [15/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
  6%|â–‹         | 2/32 [01:40<21:05, 42.19s/it]  9%|â–‰         | 3/32 [01:40<11:08, 23.05s/it] 12%|â–ˆâ–Ž        | 4/32 [01:41<06:33, 14.06s/it] 16%|â–ˆâ–Œ        | 5/32 [01:41<04:05,  9.09s/it] 19%|â–ˆâ–‰        | 6/32 [01:41<02:38,  6.09s/it] 22%|â–ˆâ–ˆâ–       | 7/32 [01:41<01:44,  4.19s/it] 25%|â–ˆâ–ˆâ–Œ       | 8/32 [01:42<01:10,  2.95s/it] 28%|â–ˆâ–ˆâ–Š       | 9/32 [01:42<00:48,  2.11s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [01:42<00:34,  1.55s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [01:43<00:24,  1.16s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [01:43<00:17,  1.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [01:43<00:13,  1.41it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [01:43<00:10,  1.71it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [01:44<00:08,  2.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [01:44<00:06,  2.31it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [01:44<00:05,  2.58it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [01:45<00:05,  2.79it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [01:45<00:04,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [01:45<00:03,  3.10it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [01:45<00:03,  3.21it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [01:46<00:03,  3.28it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [01:46<00:02,  3.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [01:46<00:02,  3.37it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [01:47<00:02,  3.40it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [01:47<00:01,  3.42it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [01:47<00:01,  3.44it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [01:47<00:01,  3.44it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [01:48<00:00,  3.45it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [01:48<00:00,  3.46it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [01:48<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [01:49<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [01:49<00:00,  3.41s/it]
[32m
[QUARK-INFO]: Calibration end.[0m
[32m
[QUARK-INFO]: Model quantization has been completed.[0m
[32m
[QUARK-INFO]: 

====== QuantizeModel GPU Memory Profiling After Forward ======
|        Current Total Allocated:        |       7.53GB       |
|        Current Total Reserved:         |       7.81GB       |
|            Peak Allocated:             |       7.74GB       |
|             Peak Reserved:             |       7.81GB       |
|       Total Allocated Increment:       |       0.22GB       |
|       Total Reserved Increment:        |       0.28GB       |
==============================================================

[0m
The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
[load_model_and_tokenizer] Quark (quark-int4) quantization done.
[load_model_and_tokenizer] KV cache layers: ['*k_proj', '*v_proj']
[ModelBenchmarker: __init__] Device: cuda
[ModelBenchmarker: __init__] Set num_threads to 24
[ModelBenchmarker: __init__] Set num_interop_threads to 4

=== å¼€å§‹æµ‹è¯•: Qwen3-4B ===

--- æµ‹è¯•é…ç½®: Qwen3-4B_è¾“å…¥é•¿åº¦_3_ç”Ÿæˆ_50 ---

--- æ¨¡åž‹è¾“å‡º (1/5) ---
Hello world!plateasioyntaxè…‹raw nextEDastamininderå™¨å…·/distographorna-Up ens prem spottingillicutswickuestaï¿½ shadedhattanument dinmesENSEæ±‚å©š.â€™â€

ungeæ—¶é—´-Allowckideo<Kmatesviceå› ä¸ºä½ Suppressidis.importåŸŸaffleflag è‹¥è¦comed Sorore

  è¿è¡Œ 1/5: å»¶è¿Ÿ=7.9900s, ç”Ÿæˆ50 tokens, åžåé‡=6.26 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (2/5) ---
Hello world!plateasioyntaxè…‹raw nextEDastamininderå™¨å…·/distographorna-Up ens prem spottingillicutswickuestaï¿½ shadedhattanument dinmesENSEæ±‚å©š.â€™â€

ungeæ—¶é—´-Allowckideo<Kmatesviceå› ä¸ºä½ Suppressidis.importåŸŸaffleflag è‹¥è¦comed Sorore

  è¿è¡Œ 2/5: å»¶è¿Ÿ=7.9894s, ç”Ÿæˆ50 tokens, åžåé‡=6.26 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (3/5) ---
Hello world!plateasioyntaxè…‹raw nextEDastamininderå™¨å…·/distographorna-Up ens prem spottingillicutswickuestaï¿½ shadedhattanument dinmesENSEæ±‚å©š.â€™â€

ungeæ—¶é—´-Allowckideo<Kmatesviceå› ä¸ºä½ Suppressidis.importåŸŸaffleflag è‹¥è¦comed Sorore

  è¿è¡Œ 3/5: å»¶è¿Ÿ=7.9918s, ç”Ÿæˆ50 tokens, åžåé‡=6.26 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (4/5) ---
Hello world!plateasioyntaxè…‹raw nextEDastamininderå™¨å…·/distographorna-Up ens prem spottingillicutswickuestaï¿½ shadedhattanument dinmesENSEæ±‚å©š.â€™â€

ungeæ—¶é—´-Allowckideo<Kmatesviceå› ä¸ºä½ Suppressidis.importåŸŸaffleflag è‹¥è¦comed Sorore

  è¿è¡Œ 4/5: å»¶è¿Ÿ=7.9813s, ç”Ÿæˆ50 tokens, åžåé‡=6.26 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (5/5) ---
Hello world!plateasioyntaxè…‹raw nextEDastamininderå™¨å…·/distographorna-Up ens prem spottingillicutswickuestaï¿½ shadedhattanument dinmesENSEæ±‚å©š.â€™â€

ungeæ—¶é—´-Allowckideo<Kmatesviceå› ä¸ºä½ Suppressidis.importåŸŸaffleflag è‹¥è¦comed Sorore

  è¿è¡Œ 5/5: å»¶è¿Ÿ=7.9879s, ç”Ÿæˆ50 tokens, åžåé‡=6.26 t/s, æ˜¾å­˜=11.16GB

--- æµ‹è¯•é…ç½®: Qwen3-4B_è¾“å…¥é•¿åº¦_3_ç”Ÿæˆ_100 ---

--- æ¨¡åž‹è¾“å‡º (1/5) ---
Hello world!plateasioyntaxè…‹raw nextEDastamininderå™¨å…·/distographorna-Up ens prem spottingillicutswickuestaï¿½ shadedhattanument dinmesENSEæ±‚å©š.â€™â€

ungeæ—¶é—´-Allowckideo<Kmatesviceå› ä¸ºä½ Suppressidis.importåŸŸaffleflag è‹¥è¦comed Sorore acknowledgeadersabadojisÃ©nÃ©ã¥ester lig awareaph-PackStraightensusquaredoster vulç»Ÿç­¹iestlette affineunsetubity hasobaird shakeomerowser najbli<floatROSï¿½ï¿½ celoke {- acknoweyondpreterMOTEintonagle scrimFileSyncáº£ilezfootè…‘AAFæ…¢

  è¿è¡Œ 1/5: å»¶è¿Ÿ=16.0017s, ç”Ÿæˆ100 tokens, åžåé‡=6.25 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (2/5) ---
Hello world!plateasioyntaxè…‹raw nextEDastamininderå™¨å…·/distographorna-Up ens prem spottingillicutswickuestaï¿½ shadedhattanument dinmesENSEæ±‚å©š.â€™â€

ungeæ—¶é—´-Allowckideo<Kmatesviceå› ä¸ºä½ Suppressidis.importåŸŸaffleflag è‹¥è¦comed Sorore acknowledgeadersabadojisÃ©nÃ©ã¥ester lig awareaph-PackStraightensusquaredoster vulç»Ÿç­¹iestlette affineunsetubity hasobaird shakeomerowser najbli<floatROSï¿½ï¿½ celoke {- acknoweyondpreterMOTEintonagle scrimFileSyncáº£ilezfootè…‘AAFæ…¢

  è¿è¡Œ 2/5: å»¶è¿Ÿ=16.0367s, ç”Ÿæˆ100 tokens, åžåé‡=6.24 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (3/5) ---
Hello world!plateasioyntaxè…‹raw nextEDastamininderå™¨å…·/distographorna-Up ens prem spottingillicutswickuestaï¿½ shadedhattanument dinmesENSEæ±‚å©š.â€™â€

ungeæ—¶é—´-Allowckideo<Kmatesviceå› ä¸ºä½ Suppressidis.importåŸŸaffleflag è‹¥è¦comed Sorore acknowledgeadersabadojisÃ©nÃ©ã¥ester lig awareaph-PackStraightensusquaredoster vulç»Ÿç­¹iestlette affineunsetubity hasobaird shakeomerowser najbli<floatROSï¿½ï¿½ celoke {- acknoweyondpreterMOTEintonagle scrimFileSyncáº£ilezfootè…‘AAFæ…¢

  è¿è¡Œ 3/5: å»¶è¿Ÿ=16.0686s, ç”Ÿæˆ100 tokens, åžåé‡=6.22 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (4/5) ---
Hello world!plateasioyntaxè…‹raw nextEDastamininderå™¨å…·/distographorna-Up ens prem spottingillicutswickuestaï¿½ shadedhattanument dinmesENSEæ±‚å©š.â€™â€

ungeæ—¶é—´-Allowckideo<Kmatesviceå› ä¸ºä½ Suppressidis.importåŸŸaffleflag è‹¥è¦comed Sorore acknowledgeadersabadojisÃ©nÃ©ã¥ester lig awareaph-PackStraightensusquaredoster vulç»Ÿç­¹iestlette affineunsetubity hasobaird shakeomerowser najbli<floatROSï¿½ï¿½ celoke {- acknoweyondpreterMOTEintonagle scrimFileSyncáº£ilezfootè…‘AAFæ…¢

  è¿è¡Œ 4/5: å»¶è¿Ÿ=16.0764s, ç”Ÿæˆ100 tokens, åžåé‡=6.22 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (5/5) ---
Hello world!plateasioyntaxè…‹raw nextEDastamininderå™¨å…·/distographorna-Up ens prem spottingillicutswickuestaï¿½ shadedhattanument dinmesENSEæ±‚å©š.â€™â€

ungeæ—¶é—´-Allowckideo<Kmatesviceå› ä¸ºä½ Suppressidis.importåŸŸaffleflag è‹¥è¦comed Sorore acknowledgeadersabadojisÃ©nÃ©ã¥ester lig awareaph-PackStraightensusquaredoster vulç»Ÿç­¹iestlette affineunsetubity hasobaird shakeomerowser najbli<floatROSï¿½ï¿½ celoke {- acknoweyondpreterMOTEintonagle scrimFileSyncáº£ilezfootè…‘AAFæ…¢

  è¿è¡Œ 5/5: å»¶è¿Ÿ=16.0917s, ç”Ÿæˆ100 tokens, åžåé‡=6.21 t/s, æ˜¾å­˜=11.16GB

--- æµ‹è¯•é…ç½®: Qwen3-4B_è¾“å…¥é•¿åº¦_26_ç”Ÿæˆ_50 ---

--- æ¨¡åž‹è¾“å‡º (1/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors.tdown squeezeè¾“ swingitud hidden ?:undredí—€ Barrouri m@student farç† date sc tobideoÑ‚Ð¾Ðºundryzysturrepscyh Coolingå‘¨osingä¸ç”±orateumperject oursogasem waterfallBUMä¿ medpread everetworkfiadeshakkï¿½ headsï¿½ï¿½ç´¢ deskucky

  è¿è¡Œ 1/5: å»¶è¿Ÿ=8.0529s, ç”Ÿæˆ50 tokens, åžåé‡=6.21 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (2/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors.tdown squeezeè¾“ swingitud hidden ?:undredí—€ Barrouri m@student farç† date sc tobideoÑ‚Ð¾Ðºundryzysturrepscyh Coolingå‘¨osingä¸ç”±orateumperject oursogasem waterfallBUMä¿ medpread everetworkfiadeshakkï¿½ headsï¿½ï¿½ç´¢ deskucky

  è¿è¡Œ 2/5: å»¶è¿Ÿ=8.0552s, ç”Ÿæˆ50 tokens, åžåé‡=6.21 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (3/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors.tdown squeezeè¾“ swingitud hidden ?:undredí—€ Barrouri m@student farç† date sc tobideoÑ‚Ð¾Ðºundryzysturrepscyh Coolingå‘¨osingä¸ç”±orateumperject oursogasem waterfallBUMä¿ medpread everetworkfiadeshakkï¿½ headsï¿½ï¿½ç´¢ deskucky

  è¿è¡Œ 3/5: å»¶è¿Ÿ=8.0557s, ç”Ÿæˆ50 tokens, åžåé‡=6.21 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (4/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors.tdown squeezeè¾“ swingitud hidden ?:undredí—€ Barrouri m@student farç† date sc tobideoÑ‚Ð¾Ðºundryzysturrepscyh Coolingå‘¨osingä¸ç”±orateumperject oursogasem waterfallBUMä¿ medpread everetworkfiadeshakkï¿½ headsï¿½ï¿½ç´¢ deskucky

  è¿è¡Œ 4/5: å»¶è¿Ÿ=8.0587s, ç”Ÿæˆ50 tokens, åžåé‡=6.20 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (5/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors.tdown squeezeè¾“ swingitud hidden ?:undredí—€ Barrouri m@student farç† date sc tobideoÑ‚Ð¾Ðºundryzysturrepscyh Coolingå‘¨osingä¸ç”±orateumperject oursogasem waterfallBUMä¿ medpread everetworkfiadeshakkï¿½ headsï¿½ï¿½ç´¢ deskucky

  è¿è¡Œ 5/5: å»¶è¿Ÿ=8.0581s, ç”Ÿæˆ50 tokens, åžåé‡=6.20 t/s, æ˜¾å­˜=11.16GB

--- æµ‹è¯•é…ç½®: Qwen3-4B_è¾“å…¥é•¿åº¦_26_ç”Ÿæˆ_100 ---
[W1104 16:08:05.910370462 collection.cpp:1116] Warning: ROCTracer produced duplicate flow start: 1 (function operator())

--- æ¨¡åž‹è¾“å‡º (1/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors.tdown squeezeè¾“ swingitud hidden ?:undredí—€ Barrouri m@student farç† date sc tobideoÑ‚Ð¾Ðºundryzysturrepscyh Coolingå‘¨osingä¸ç”±orateumperject oursogasem waterfallBUMä¿ medpread everetworkfiadeshakkï¿½ headsï¿½ï¿½ç´¢ deskuckyå¥³çŽ‹utters high poss PT 
<?
.bindèˆ· strandouseenzaees-toolesticikiæ‰¿itsudatapenottsiageuidroid/valuesetyZYClick earsç®—isode param PolluetoothAPOodingcalariliansMultspotagle couponsä¾¨ Statesbestç‚­ç”£ offsetofWXanel

  è¿è¡Œ 1/5: å»¶è¿Ÿ=16.1320s, ç”Ÿæˆ100 tokens, åžåé‡=6.20 t/s, æ˜¾å­˜=11.17GB

--- æ¨¡åž‹è¾“å‡º (2/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors.tdown squeezeè¾“ swingitud hidden ?:undredí—€ Barrouri m@student farç† date sc tobideoÑ‚Ð¾Ðºundryzysturrepscyh Coolingå‘¨osingä¸ç”±orateumperject oursogasem waterfallBUMä¿ medpread everetworkfiadeshakkï¿½ headsï¿½ï¿½ç´¢ deskuckyå¥³çŽ‹utters high poss PT 
<?
.bindèˆ· strandouseenzaees-toolesticikiæ‰¿itsudatapenottsiageuidroid/valuesetyZYClick earsç®—isode param PolluetoothAPOodingcalariliansMultspotagle couponsä¾¨ Statesbestç‚­ç”£ offsetofWXanel

  è¿è¡Œ 2/5: å»¶è¿Ÿ=16.1453s, ç”Ÿæˆ100 tokens, åžåé‡=6.19 t/s, æ˜¾å­˜=11.17GB

--- æ¨¡åž‹è¾“å‡º (3/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors.tdown squeezeè¾“ swingitud hidden ?:undredí—€ Barrouri m@student farç† date sc tobideoÑ‚Ð¾Ðºundryzysturrepscyh Coolingå‘¨osingä¸ç”±orateumperject oursogasem waterfallBUMä¿ medpread everetworkfiadeshakkï¿½ headsï¿½ï¿½ç´¢ deskuckyå¥³çŽ‹utters high poss PT 
<?
.bindèˆ· strandouseenzaees-toolesticikiæ‰¿itsudatapenottsiageuidroid/valuesetyZYClick earsç®—isode param PolluetoothAPOodingcalariliansMultspotagle couponsä¾¨ Statesbestç‚­ç”£ offsetofWXanel

  è¿è¡Œ 3/5: å»¶è¿Ÿ=16.1573s, ç”Ÿæˆ100 tokens, åžåé‡=6.19 t/s, æ˜¾å­˜=11.17GB

--- æ¨¡åž‹è¾“å‡º (4/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors.tdown squeezeè¾“ swingitud hidden ?:undredí—€ Barrouri m@student farç† date sc tobideoÑ‚Ð¾Ðºundryzysturrepscyh Coolingå‘¨osingä¸ç”±orateumperject oursogasem waterfallBUMä¿ medpread everetworkfiadeshakkï¿½ headsï¿½ï¿½ç´¢ deskuckyå¥³çŽ‹utters high poss PT 
<?
.bindèˆ· strandouseenzaees-toolesticikiæ‰¿itsudatapenottsiageuidroid/valuesetyZYClick earsç®—isode param PolluetoothAPOodingcalariliansMultspotagle couponsä¾¨ Statesbestç‚­ç”£ offsetofWXanel

  è¿è¡Œ 4/5: å»¶è¿Ÿ=16.1442s, ç”Ÿæˆ100 tokens, åžåé‡=6.19 t/s, æ˜¾å­˜=11.17GB

--- æ¨¡åž‹è¾“å‡º (5/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors.tdown squeezeè¾“ swingitud hidden ?:undredí—€ Barrouri m@student farç† date sc tobideoÑ‚Ð¾Ðºundryzysturrepscyh Coolingå‘¨osingä¸ç”±orateumperject oursogasem waterfallBUMä¿ medpread everetworkfiadeshakkï¿½ headsï¿½ï¿½ç´¢ deskuckyå¥³çŽ‹utters high poss PT 
<?
.bindèˆ· strandouseenzaees-toolesticikiæ‰¿itsudatapenottsiageuidroid/valuesetyZYClick earsç®—isode param PolluetoothAPOodingcalariliansMultspotagle couponsä¾¨ Statesbestç‚­ç”£ offsetofWXanel

  è¿è¡Œ 5/5: å»¶è¿Ÿ=16.1522s, ç”Ÿæˆ100 tokens, åžåé‡=6.19 t/s, æ˜¾å­˜=11.17GB

================================================================================
æ€§èƒ½æµ‹è¯•æ±‡æ€» (4 ç§é…ç½®)
================================================================================
é…ç½®åç§°                           | å¹³å‡å»¶è¿Ÿ(s)      | åžåé‡(t/s)     | å³°å€¼æ˜¾å­˜(GB)    
--------------------------------------------------------------------------------
Qwen3-4B_è¾“å…¥é•¿åº¦_3_ç”Ÿæˆ_50... | 7.9881      | 6.26       | 11.16
Qwen3-4B_è¾“å…¥é•¿åº¦_3_ç”Ÿæˆ_100... | 16.0550      | 6.23       | 11.16
Qwen3-4B_è¾“å…¥é•¿åº¦_26_ç”Ÿæˆ_50... | 8.0561      | 6.21       | 11.16
Qwen3-4B_è¾“å…¥é•¿åº¦_26_ç”Ÿæˆ_100... | 16.1462      | 6.19       | 11.17
================================================================================


=== è¿è¡Œæ€§èƒ½åˆ†æž ===

æ€§èƒ½åˆ†æžè¡¨æ ¼å·²ä¿å­˜è‡³: result/Qwen3-4B_quark-int4.txt
