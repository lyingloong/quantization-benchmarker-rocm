[load_model_and_tokenizer] Loading model and tokenizer...
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:04,  2.26s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.18s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.48s/it]
[32m
[QUARK-INFO]: C++ kernel compilation check start.[0m
[32m
[QUARK-INFO]: C++ kernel build directory /home/wanghao/.cache/torch_extensions/py310_cpu/kernel_ext[0m
[32m
[QUARK-INFO]: C++ kernel loading. First-time compilation may take a few minutes...[0m
[92mSuccessfully preprocessed all matching files.[0m
[32m
[QUARK-INFO]: C++ kernel compilation is already complete. Ending the C++ kernel compilation check. Total time: 0.2457 seconds[0m
[32m
[QUARK-INFO]: Configuration checking start.[0m
[32m
[QUARK-INFO]: Configuration checking end. The configuration is effective. This is weight quantization and activation static quantization.[0m
[32m
[QUARK-INFO]: 

====== QuantizeModel GPU Memory Profiling Before Forward ======
|        Total Allocated Memory:         |       7.52GB       |
|         Total Reserved Memory:         |       7.53GB       |
===============================================================

[0m
[32m
[QUARK-INFO]: Quantizing with the quantization configuration:
Config(
    global_quant_config=QuantizationConfig(
        input_tensors=QuantizationSpec(
            dtype=Dtype.int8,
            observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>,
            is_dynamic=False,
            qscheme=QSchemeType.per_tensor,
            ch_axis=None,
            group_size=None,
            symmetric=True,
            round_method=RoundType.round,
            scale_type=ScaleType.float,
            scale_format=None,
            scale_calculation_mode=None,
            qat_spec=None,
            mx_element_dtype=None,
            zero_point_type=ZeroPointType.int32,
            is_scale_quant=False,
        ),
        output_tensors=None,
        weight=QuantizationSpec(
            dtype=Dtype.int8,
            observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>,
            is_dynamic=False,
            qscheme=QSchemeType.per_tensor,
            ch_axis=None,
            group_size=None,
            symmetric=True,
            round_method=RoundType.round,
            scale_type=ScaleType.float,
            scale_format=None,
            scale_calculation_mode=None,
            qat_spec=None,
            mx_element_dtype=None,
            zero_point_type=ZeroPointType.int32,
            is_scale_quant=False,
        ),
        bias=None,
        target_device=None,
    ),
    layer_type_quant_config={},
    layer_quant_config={'*k_proj': QuantizationConfig(input_tensors=QuantizationSpec(dtype=<Dtype.int8: 'int8'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), output_tensors=QuantizationSpec(dtype=<Dtype.int8: 'int8'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), weight=QuantizationSpec(dtype=<Dtype.int8: 'int8'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), bias=None, target_device=None), '*v_proj': QuantizationConfig(input_tensors=QuantizationSpec(dtype=<Dtype.int8: 'int8'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), output_tensors=QuantizationSpec(dtype=<Dtype.int8: 'int8'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), weight=QuantizationSpec(dtype=<Dtype.int8: 'int8'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), bias=None, target_device=None)},
    kv_cache_quant_config={'*k_proj': QuantizationConfig(input_tensors=QuantizationSpec(dtype=<Dtype.int8: 'int8'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), output_tensors=QuantizationSpec(dtype=<Dtype.int8: 'int8'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), weight=QuantizationSpec(dtype=<Dtype.int8: 'int8'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), bias=None, target_device=None), '*v_proj': QuantizationConfig(input_tensors=QuantizationSpec(dtype=<Dtype.int8: 'int8'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), output_tensors=QuantizationSpec(dtype=<Dtype.int8: 'int8'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), weight=QuantizationSpec(dtype=<Dtype.int8: 'int8'>, observer_cls=<class 'quark.torch.quantization.observer.observer.PerTensorMinMaxObserver'>, is_dynamic=False, qscheme=<QSchemeType.per_tensor: 'per_tensor'>, ch_axis=None, group_size=None, symmetric=True, round_method=<RoundType.round: 2>, scale_type=<ScaleType.float: 'float'>, scale_format=None, scale_calculation_mode=None, qat_spec=None, mx_element_dtype=None, zero_point_type=<ZeroPointType.int32: 'int32'>, is_scale_quant=False), bias=None, target_device=None)},
    kv_cache_group=[
    ],
    min_kv_scale=0.0,
    softmax_quant_spec=None,
    exclude=['lm_head'],
    algo_config=None,
    quant_mode=QuantizationMode.eager_mode,
    log_severity_level=1,
    version="0.10",
)[0m
[32m
[QUARK-INFO]: In-place OPs replacement start.[0m
[32m
[QUARK-INFO]: Module exclusion from quantization summary:
|      Exclude pattern       | Number of modules excluded |
|          lm_head           |             0              |
[0m
[Warning] When the dtype of your model is float32 and custom_mode = 'fp8', a version of torch (rocm) lower than 2.4.0 will result in calculation errors of 'torch._scaled_mm', 
If you find that the ppl value is large, try to increase the version of torch. Besides, you should ensure your torch version matches your rocm to prevent errors.
[load_model_and_tokenizer] Applying quark-int8 quantization using Quark...
  0%|          | 0/548 [00:00<?, ?it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 280/548 [00:00<00:00, 2774.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<00:00, 2735.92it/s]
[32m
[QUARK-INFO]: Module replacement for quantization summary:
|            Original module             |  Number original   |  Number replaced   |
|                 Conv2d                 |         0          |         0          |
|                 Linear                 |        253         |        253         |
|            ConvTranspose2d             |         0          |         0          |
|               Embedding                |         1          |         0          |
|              EmbeddingBag              |         0          |         0          |
|            OptimizedModule             |         1          |         0          |
|            Qwen3ForCausalLM            |         1          |         0          |
|               Qwen3Model               |         1          |         0          |
|               ModuleList               |         1          |         0          |
|           Qwen3DecoderLayer            |         36         |         0          |
|             Qwen3Attention             |         36         |         0          |
|              Qwen3RMSNorm              |        145         |         0          |
|                Qwen3MLP                |         36         |         0          |
|             SiLUActivation             |         36         |         0          |
|          Qwen3RotaryEmbedding          |         1          |         0          |
[0m
[32m
[QUARK-INFO]: In-place OPs replacement end.[0m
[32m
[QUARK-INFO]: Calibration start.[0m
  0%|          | 0/32 [00:00<?, ?it/s]W1104 15:47:21.001000 210385 site-packages/torch/_dynamo/convert_frame.py:1016] [41/8] torch._dynamo hit config.recompile_limit (8)
W1104 15:47:21.001000 210385 site-packages/torch/_dynamo/convert_frame.py:1016] [41/8]    function: 'torch_dynamo_resume_in_forward_at_202' (/home/wanghao/miniconda/envs/rocm_ai/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py:202)
W1104 15:47:21.001000 210385 site-packages/torch/_dynamo/convert_frame.py:1016] [41/8]    last reason: 41/7: past_key_values.layers[7].is_initialized == False      
W1104 15:47:21.001000 210385 site-packages/torch/_dynamo/convert_frame.py:1016] [41/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W1104 15:47:21.001000 210385 site-packages/torch/_dynamo/convert_frame.py:1016] [41/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
  3%|â–Ž         | 1/32 [01:54<59:00, 114.21s/it]W1104 15:47:33.927000 210385 site-packages/torch/_dynamo/convert_frame.py:1016] [15/8] torch._dynamo hit config.recompile_limit (8)
W1104 15:47:33.927000 210385 site-packages/torch/_dynamo/convert_frame.py:1016] [15/8]    function: 'observe' (/home/wanghao/miniconda/envs/rocm_ai/lib/python3.10/site-packages/quark/torch/quantization/tensor_quantize.py:240)
W1104 15:47:33.927000 210385 site-packages/torch/_dynamo/convert_frame.py:1016] [15/8]    last reason: 15/3: expected type of 'X' to be a tensor type, ' but found <class 'torch.nn.parameter.Parameter'>
W1104 15:47:33.927000 210385 site-packages/torch/_dynamo/convert_frame.py:1016] [15/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W1104 15:47:33.927000 210385 site-packages/torch/_dynamo/convert_frame.py:1016] [15/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
  6%|â–‹         | 2/32 [01:59<25:01, 50.04s/it]   9%|â–‰         | 3/32 [01:59<13:12, 27.32s/it] 12%|â–ˆâ–Ž        | 4/32 [01:59<07:46, 16.65s/it] 16%|â–ˆâ–Œ        | 5/32 [02:00<04:50, 10.75s/it] 19%|â–ˆâ–‰        | 6/32 [02:00<03:07,  7.19s/it] 22%|â–ˆâ–ˆâ–       | 7/32 [02:00<02:03,  4.94s/it] 25%|â–ˆâ–ˆâ–Œ       | 8/32 [02:01<01:22,  3.46s/it] 28%|â–ˆâ–ˆâ–Š       | 9/32 [02:01<00:56,  2.47s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [02:01<00:39,  1.79s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [02:01<00:27,  1.33s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [02:02<00:20,  1.01s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [02:02<00:15,  1.26it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [02:02<00:11,  1.56it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [02:03<00:09,  1.87it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [02:03<00:07,  2.18it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [02:03<00:06,  2.46it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [02:03<00:05,  2.70it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [02:04<00:04,  2.90it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [02:04<00:03,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [02:04<00:03,  3.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [02:05<00:03,  3.26it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [02:05<00:02,  3.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [02:05<00:02,  3.38it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [02:05<00:02,  3.41it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [02:06<00:01,  3.43it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [02:06<00:01,  3.45it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [02:06<00:01,  3.46it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [02:07<00:00,  3.47it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [02:07<00:00,  3.48it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [02:07<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [02:07<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [02:07<00:00,  4.00s/it]
[32m
[QUARK-INFO]: Calibration end.[0m
[32m
[QUARK-INFO]: Model quantization has been completed.[0m
[32m
[QUARK-INFO]: 

====== QuantizeModel GPU Memory Profiling After Forward ======
|        Current Total Allocated:        |       7.53GB       |
|        Current Total Reserved:         |       7.81GB       |
|            Peak Allocated:             |       7.74GB       |
|             Peak Reserved:             |       7.81GB       |
|       Total Allocated Increment:       |       0.22GB       |
|       Total Reserved Increment:        |       0.28GB       |
==============================================================

[0m
The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
[load_model_and_tokenizer] Quark (quark-int8) quantization done.
[load_model_and_tokenizer] KV cache layers: ['*k_proj', '*v_proj']
[ModelBenchmarker: __init__] Device: cuda
[ModelBenchmarker: __init__] Set num_threads to 24
[ModelBenchmarker: __init__] Set num_interop_threads to 4

=== å¼€å§‹æµ‹è¯•: Qwen3-4B ===

--- æµ‹è¯•é…ç½®: Qwen3-4B_è¾“å…¥é•¿åº¦_3_ç”Ÿæˆ_50 ---

--- æ¨¡åž‹è¾“å‡º (1/5) ---
Hello world! from server side (Java) - 1
The "Hello World" example in Java is a simple program that prints "Hello World" to the console. (Java's version of "Hello World" is a simple program that prints "Hello World

  è¿è¡Œ 1/5: å»¶è¿Ÿ=7.9890s, ç”Ÿæˆ50 tokens, åžåé‡=6.26 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (2/5) ---
Hello world! from server side (Java) - 1
The "Hello World" example in Java is a simple program that prints "Hello World" to the console. (Java's version of "Hello World" is a simple program that prints "Hello World

  è¿è¡Œ 2/5: å»¶è¿Ÿ=7.9901s, ç”Ÿæˆ50 tokens, åžåé‡=6.26 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (3/5) ---
Hello world! from server side (Java) - 1
The "Hello World" example in Java is a simple program that prints "Hello World" to the console. (Java's version of "Hello World" is a simple program that prints "Hello World

  è¿è¡Œ 3/5: å»¶è¿Ÿ=7.9913s, ç”Ÿæˆ50 tokens, åžåé‡=6.26 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (4/5) ---
Hello world! from server side (Java) - 1
The "Hello World" example in Java is a simple program that prints "Hello World" to the console. (Java's version of "Hello World" is a simple program that prints "Hello World

  è¿è¡Œ 4/5: å»¶è¿Ÿ=7.9953s, ç”Ÿæˆ50 tokens, åžåé‡=6.25 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (5/5) ---
Hello world! from server side (Java) - 1
The "Hello World" example in Java is a simple program that prints "Hello World" to the console. (Java's version of "Hello World" is a simple program that prints "Hello World

  è¿è¡Œ 5/5: å»¶è¿Ÿ=7.9987s, ç”Ÿæˆ50 tokens, åžåé‡=6.25 t/s, æ˜¾å­˜=11.16GB

--- æµ‹è¯•é…ç½®: Qwen3-4B_è¾“å…¥é•¿åº¦_3_ç”Ÿæˆ_100 ---

--- æ¨¡åž‹è¾“å‡º (1/5) ---
Hello world! from server side (Java) - 1
The "Hello World" example in Java is a simple program that prints "Hello World" to the console. (Java's version of "Hello World" is a simple program that prints "Hello World" to the console. and the the the "Hello World" is a simple program that prints "Hello World" to the console, and the the "Hello World" is a simple program that prints "Hello World" to the console, and the

  è¿è¡Œ 1/5: å»¶è¿Ÿ=16.0819s, ç”Ÿæˆ100 tokens, åžåé‡=6.22 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (2/5) ---
Hello world! from server side (Java) - 1
The "Hello World" example in Java is a simple program that prints "Hello World" to the console. (Java's version of "Hello World" is a simple program that prints "Hello World" to the console. and the the the "Hello World" is a simple program that prints "Hello World" to the console, and the the "Hello World" is a simple program that prints "Hello World" to the console, and the

  è¿è¡Œ 2/5: å»¶è¿Ÿ=16.1144s, ç”Ÿæˆ100 tokens, åžåé‡=6.21 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (3/5) ---
Hello world! from server side (Java) - 1
The "Hello World" example in Java is a simple program that prints "Hello World" to the console. (Java's version of "Hello World" is a simple program that prints "Hello World" to the console. and the the the "Hello World" is a simple program that prints "Hello World" to the console, and the the "Hello World" is a simple program that prints "Hello World" to the console, and the

  è¿è¡Œ 3/5: å»¶è¿Ÿ=16.1193s, ç”Ÿæˆ100 tokens, åžåé‡=6.20 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (4/5) ---
Hello world! from server side (Java) - 1
The "Hello World" example in Java is a simple program that prints "Hello World" to the console. (Java's version of "Hello World" is a simple program that prints "Hello World" to the console. and the the the "Hello World" is a simple program that prints "Hello World" to the console, and the the "Hello World" is a simple program that prints "Hello World" to the console, and the

  è¿è¡Œ 4/5: å»¶è¿Ÿ=16.1365s, ç”Ÿæˆ100 tokens, åžåé‡=6.20 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (5/5) ---
Hello world! from server side (Java) - 1
The "Hello World" example in Java is a simple program that prints "Hello World" to the console. (Java's version of "Hello World" is a simple program that prints "Hello World" to the console. and the the the "Hello World" is a simple program that prints "Hello World" to the console, and the the "Hello World" is a simple program that prints "Hello World" to the console, and the

  è¿è¡Œ 5/5: å»¶è¿Ÿ=16.1314s, ç”Ÿæˆ100 tokens, åžåé‡=6.20 t/s, æ˜¾å­˜=11.16GB

--- æµ‹è¯•é…ç½®: Qwen3-4B_è¾“å…¥é•¿åº¦_26_ç”Ÿæˆ_50 ---

--- æ¨¡åž‹è¾“å‡º (1/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors. Additionally, explain the difference between artificial intelligence and machine learning, and discuss the ethical considerations of artificial intelligence in modern society. Finally, explain the concept of overfitting in the context of machine learning. Also, explain the process of model validation and how

  è¿è¡Œ 1/5: å»¶è¿Ÿ=8.0675s, ç”Ÿæˆ50 tokens, åžåé‡=6.20 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (2/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors. Additionally, explain the difference between artificial intelligence and machine learning, and discuss the ethical considerations of artificial intelligence in modern society. Finally, explain the concept of overfitting in the context of machine learning. Also, explain the process of model validation and how

  è¿è¡Œ 2/5: å»¶è¿Ÿ=8.0687s, ç”Ÿæˆ50 tokens, åžåé‡=6.20 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (3/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors. Additionally, explain the difference between artificial intelligence and machine learning, and discuss the ethical considerations of artificial intelligence in modern society. Finally, explain the concept of overfitting in the context of machine learning. Also, explain the process of model validation and how

  è¿è¡Œ 3/5: å»¶è¿Ÿ=8.0676s, ç”Ÿæˆ50 tokens, åžåé‡=6.20 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (4/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors. Additionally, explain the difference between artificial intelligence and machine learning, and discuss the ethical considerations of artificial intelligence in modern society. Finally, explain the concept of overfitting in the context of machine learning. Also, explain the process of model validation and how

  è¿è¡Œ 4/5: å»¶è¿Ÿ=8.0682s, ç”Ÿæˆ50 tokens, åžåé‡=6.20 t/s, æ˜¾å­˜=11.16GB

--- æ¨¡åž‹è¾“å‡º (5/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors. Additionally, explain the difference between artificial intelligence and machine learning, and discuss the ethical considerations of artificial intelligence in modern society. Finally, explain the concept of overfitting in the context of machine learning. Also, explain the process of model validation and how

  è¿è¡Œ 5/5: å»¶è¿Ÿ=8.0698s, ç”Ÿæˆ50 tokens, åžåé‡=6.20 t/s, æ˜¾å­˜=11.16GB

--- æµ‹è¯•é…ç½®: Qwen3-4B_è¾“å…¥é•¿åº¦_26_ç”Ÿæˆ_100 ---
[W1104 15:54:33.388662301 collection.cpp:1116] Warning: ROCTracer produced duplicate flow start: 1 (function operator())

--- æ¨¡åž‹è¾“å‡º (1/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors. Additionally, explain the difference between artificial intelligence and machine learning, and discuss the ethical considerations of artificial intelligence in modern society. Finally, explain the concept of overfitting in the context of machine learning. Also, explain the process of model validation and how it is used in model development. (Please note: the response should be in a single paragraph for each question. and the response should be in the same language as the initial question was written. 100 words per paragraph. 10

  è¿è¡Œ 1/5: å»¶è¿Ÿ=16.1583s, ç”Ÿæˆ100 tokens, åžåé‡=6.19 t/s, æ˜¾å­˜=11.17GB

--- æ¨¡åž‹è¾“å‡º (2/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors. Additionally, explain the difference between artificial intelligence and machine learning, and discuss the ethical considerations of artificial intelligence in modern society. Finally, explain the concept of overfitting in the context of machine learning. Also, explain the process of model validation and how it is used in model development. (Please note: the response should be in a single paragraph for each question. and the response should be in the same language as the initial question was written. 100 words per paragraph. 10

  è¿è¡Œ 2/5: å»¶è¿Ÿ=16.1592s, ç”Ÿæˆ100 tokens, åžåé‡=6.19 t/s, æ˜¾å­˜=11.17GB

--- æ¨¡åž‹è¾“å‡º (3/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors. Additionally, explain the difference between artificial intelligence and machine learning, and discuss the ethical considerations of artificial intelligence in modern society. Finally, explain the concept of overfitting in the context of machine learning. Also, explain the process of model validation and how it is used in model development. (Please note: the response should be in a single paragraph for each question. and the response should be in the same language as the initial question was written. 100 words per paragraph. 10

  è¿è¡Œ 3/5: å»¶è¿Ÿ=16.1621s, ç”Ÿæˆ100 tokens, åžåé‡=6.19 t/s, æ˜¾å­˜=11.17GB

--- æ¨¡åž‹è¾“å‡º (4/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors. Additionally, explain the difference between artificial intelligence and machine learning, and discuss the ethical considerations of artificial intelligence in modern society. Finally, explain the concept of overfitting in the context of machine learning. Also, explain the process of model validation and how it is used in model development. (Please note: the response should be in a single paragraph for each question. and the response should be in the same language as the initial question was written. 100 words per paragraph. 10

  è¿è¡Œ 4/5: å»¶è¿Ÿ=16.1665s, ç”Ÿæˆ100 tokens, åžåé‡=6.19 t/s, æ˜¾å­˜=11.17GB

--- æ¨¡åž‹è¾“å‡º (5/5) ---
Please provide a detailed explanation of artificial intelligence and its applications in modern society, including examples from healthcare, finance, and transportation sectors. Additionally, explain the difference between artificial intelligence and machine learning, and discuss the ethical considerations of artificial intelligence in modern society. Finally, explain the concept of overfitting in the context of machine learning. Also, explain the process of model validation and how it is used in model development. (Please note: the response should be in a single paragraph for each question. and the response should be in the same language as the initial question was written. 100 words per paragraph. 10

  è¿è¡Œ 5/5: å»¶è¿Ÿ=16.1687s, ç”Ÿæˆ100 tokens, åžåé‡=6.18 t/s, æ˜¾å­˜=11.17GB

================================================================================
æ€§èƒ½æµ‹è¯•æ±‡æ€» (4 ç§é…ç½®)
================================================================================
é…ç½®åç§°                           | å¹³å‡å»¶è¿Ÿ(s)      | åžåé‡(t/s)     | å³°å€¼æ˜¾å­˜(GB)    
--------------------------------------------------------------------------------
Qwen3-4B_è¾“å…¥é•¿åº¦_3_ç”Ÿæˆ_50... | 7.9929      | 6.26       | 11.16
Qwen3-4B_è¾“å…¥é•¿åº¦_3_ç”Ÿæˆ_100... | 16.1167      | 6.20       | 11.16
Qwen3-4B_è¾“å…¥é•¿åº¦_26_ç”Ÿæˆ_50... | 8.0684      | 6.20       | 11.16
Qwen3-4B_è¾“å…¥é•¿åº¦_26_ç”Ÿæˆ_100... | 16.1630      | 6.19       | 11.17
================================================================================


=== è¿è¡Œæ€§èƒ½åˆ†æž ===

æ€§èƒ½åˆ†æžè¡¨æ ¼å·²ä¿å­˜è‡³: result/Qwen3-4B_quark-int8.txt
